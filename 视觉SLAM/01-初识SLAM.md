# 初识SLAM

### 1. 视觉`slam`中的相机类型

视觉`slam`项目中主要用到的相机类型包括三种：

+ 单目相机
+ 双目相机
+ 深度相机

#### 1.1 单目相机（Monocular）

​	单目相机的单张图像无法获取像素的深度信息，想要获取相机的深度信息，需要对相机进行平移，但是这样获取的深度信息仅仅是一个相对的值，我们无法确定真实的尺度。

#### 1.2 双目相机（Stereo）

​	双目相机通过比较左右两张图像的差距计算像素的深度信息，关于真实的尺度，由于两个相机之际的实际距离是已知的，因此可以通过这个基线来估计每个像素的空间位置。

​	使用双目相机的项目中，计算量是很大的，非常消耗计算资源。

#### 1.3 深度相机（RGB-D）

​	与双目相机类似，它可以获取每个像素距离镜头的距离，但是不同之处在于，深度相机是通过红外结构光或`Time-of-Flight`原理，像激光传感器那样，通过主动向物体发射光并接收返回的光，测量物体和相机之间的距离。这种测量是物理测量，因此计算速度快。

​	但深度相机存在测量范围窄，噪声大，视野小，易受日光影响等问题，因此深度相机多用于室内。

### 2. 经典视觉`SLAM`框架

![](.\images\经典视觉SLAM框架.png)





+  传感器数据：在视觉SLAM中主要是获取相机图像信息和预处理。
+ 视觉里程计：也称前端，估算相邻图像间相机的运动以及局部地图的样子
+ 非线性优化：也称后端，接收前端和回环检测传递的数据，对其进行优化，得到全局一致的轨迹和地图。
+ 回环检测：检测相机是否到过此位置，如果检测到回环，会将信息发送给后端进行处理。
+ 建图：根据收集到的数据建立地图。

#### 2.1 视觉里程计

![](.\images\视觉里程计示例图.png)



如上图，从相机获取到的两张相邻的图像，通过直觉可以看出右边的图像是左图左移的一定角度的结果，但是具体移动了多少度，平移了多少厘米我们很难给出一个确切的答案，但是对于视觉SLAM来说这些数据是必须要获取的。

这里我们只需要知道视觉里程计是通过相邻图像来估计相机运动并恢复场景的即可，对于具体实现将在后面的章节中进行讲解。

#### 2.2 非线性优化

了解了视觉里程计我们可以知道它完成了定位和制图，那么为什么还需要后端优化呢？这是因为视觉里程计仅仅是根据相邻的图像估计了相机的运动，这种估计是存在误差的，而且这种误差是传递的，这样就会出现累积漂移。

为了消除这种误差，我们需要后端优化，后端优化根据前端传递和回环检测传递的数据对其进行优化，主要是滤波和非线性优化算法。

#### 2.3 回环检测

回环检测主要解决位置估计随时间漂移的问题，地图存在的主要意义是让机器人知晓自己到过的地方，因此回环检测是必须的。

#### 2.4 建图

建图是指构建地图的过程，地图是对环境的描述。

+ 二维栅格地图：家用扫地机器人
+ 稀疏地图：定位
+ 稠密地图：路径规划、导航和避障